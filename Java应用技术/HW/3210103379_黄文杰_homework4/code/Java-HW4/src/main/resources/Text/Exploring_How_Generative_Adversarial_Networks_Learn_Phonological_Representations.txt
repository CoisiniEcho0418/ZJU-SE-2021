Title: Exploring How Generative Adversarial Networks Learn Phonological Representations
Authors: Jingyi Chen, Micha Elsner
Abstract: This paper explores how Generative Adversarial Networks (GANs) learn representations of phonological phenomena. We analyze how GANs encode contrastive and non-contrastive nasality in French and English vowels by applying the ciwGAN architecture (Begus, 2021). Begus claims that ciwGAN encodes linguistically meaningful representations with categorical variables in its latent space and manipulating the latent variables shows an almost one to one corresponding control of the phonological features in ciwGAN’s generated outputs. However, our results show an interactive effect of latent variables on the features in the generated outputs, which suggests the learned representations in neural networks are different from the phonological representations proposed by linguists. On the other hand, ciwGAN is able to distinguish contrastive and noncontrastive features in English and French by encoding them differently. Comparing the performance of GANs learning from different languages results in a better understanding of what language specific features contribute to developing language specific phonological representations. We also discuss the role of training data frequencies in phonological feature learning.
Cite (Informal):Exploring How Generative Adversarial Networks Learn Phonological Representations (Chen & Elsner, ACL 2023)
Year:2023
Venue:ACL
Anthology ID:2023.acl-long.175
Bibkey:chen-elsner-2023-exploring
Volume:Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
URL:https://aclanthology.org/2023.acl-long.175
PDF:https://aclanthology.org/2023.acl-long.175.pdf
Month:July
SIG:
Address:Toronto, Canada
Language:
Cite (ACL):Jingyi Chen and Micha Elsner. 2023. Exploring How Generative Adversarial Networks Learn Phonological Representations. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3115–3129, Toronto, Canada. Association for Computational Linguistics.
Editors:Anna Rogers,Jordan Boyd-Graber,Naoaki Okazaki
Note:
Pages:3115–3129
DOI:10.18653/v1/2023.acl-long.175
Publisher:Association for Computational Linguistics
BibTex: @inproceedings{chen-elsner-2023-exploring,
    title = "Exploring How Generative Adversarial Networks Learn Phonological Representations",
    author = "Chen, Jingyi  and
      Elsner, Micha",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.175",
    doi = "10.18653/v1/2023.acl-long.175",
    pages = "3115--3129",
    abstract = "This paper explores how Generative Adversarial Networks (GANs) learn representations of phonological phenomena. We analyze how GANs encode contrastive and non-contrastive nasality in French and English vowels by applying the ciwGAN architecture (Begus, 2021). Begus claims that ciwGAN encodes linguistically meaningful representations with categorical variables in its latent space and manipulating the latent variables shows an almost one to one corresponding control of the phonological features in ciwGAN{'}s generated outputs. However, our results show an interactive effect of latent variables on the features in the generated outputs, which suggests the learned representations in neural networks are different from the phonological representations proposed by linguists. On the other hand, ciwGAN is able to distinguish contrastive and noncontrastive features in English and French by encoding them differently. Comparing the performance of GANs learning from different languages results in a better understanding of what language specific features contribute to developing language specific phonological representations. We also discuss the role of training data frequencies in phonological feature learning.",
}

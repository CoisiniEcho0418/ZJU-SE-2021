Title: KIT’s Multilingual Speech Translation System for IWSLT 2023
Authors: Danni Liu, Thai Binh Nguyen, Sai Koneru, Enes Yavuz Ugan, Ngoc-Quan Pham, Tuan Nam Nguyen, Tu Anh Dinh, Carlos Mullov, Alexander Waibel, Jan Niehues
Abstract: Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks. k +0.8
Cite (Informal):KIT’s Multilingual Speech Translation System for IWSLT 2023 (Liu et al., IWSLT 2023)
Year:2023
Venue:IWSLT
Anthology ID:2023.iwslt-1.6
Bibkey:liu-etal-2023-kits
Volume:Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)
URL:https://aclanthology.org/2023.iwslt-1.6
PDF:https://aclanthology.org/2023.iwslt-1.6.pdf
Month:July
SIG:SIGSLT
Address:Toronto, Canada (in-person and online)
Language:
Cite (ACL):Danni Liu, Thai Binh Nguyen, Sai Koneru, Enes Yavuz Ugan, Ngoc-Quan Pham, Tuan Nam Nguyen, Tu Anh Dinh, Carlos Mullov, Alexander Waibel, and Jan Niehues. 2023. KIT’s Multilingual Speech Translation System for IWSLT 2023. In Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023), pages 113–122, Toronto, Canada (in-person and online). Association for Computational Linguistics.
Editors:Elizabeth Salesky,Marcello Federico,Marine Carpuat
Note:
Pages:113–122
DOI:10.18653/v1/2023.iwslt-1.6
Publisher:Association for Computational Linguistics
BibTex: @inproceedings{liu-etal-2023-kits,
    title = "{KIT}{'}s Multilingual Speech Translation System for {IWSLT} 2023",
    author = "Liu, Danni  and
      Binh Nguyen, Thai  and
      Koneru, Sai  and
      Yavuz Ugan, Enes  and
      Pham, Ngoc-Quan  and
      Nam Nguyen, Tuan  and
      Anh Dinh, Tu  and
      Mullov, Carlos  and
      Waibel, Alexander  and
      Niehues, Jan",
    editor = "Salesky, Elizabeth  and
      Federico, Marcello  and
      Carpuat, Marine",
    booktitle = "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada (in-person and online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.iwslt-1.6",
    doi = "10.18653/v1/2023.iwslt-1.6",
    pages = "113--122",
    abstract = "Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach ($k$NN-MT) for effective adaptation ($+0.8$ BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.",
}

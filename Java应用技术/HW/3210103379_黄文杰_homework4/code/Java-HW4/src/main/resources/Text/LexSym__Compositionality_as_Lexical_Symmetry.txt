Title: LexSym: Compositionality as Lexical Symmetry
Authors: Ekin Akyurek, Jacob Andreas
Abstract: In tasks like semantic parsing, instruction following, and question answering, standard deep networks fail to generalize compositionally from small datasets. Many existing approaches overcome this limitation with model architectures that enforce a compositional process of sentence interpretation. In this paper, we present a domain-general and model-agnostic formulation of compositionality as a constraint on symmetries of data distributions rather than models. Informally, we prove that whenever a task can be solved by a compositional model, there is a corresponding data augmentation scheme — a procedure for transforming examples into other well-formed examples — that imparts compositional inductive bias on any model trained to solve the same task. We describe a procedure called LexSym that discovers these transformations automatically, then applies them to training data for ordinary neural sequence models. Unlike existing compositional data augmentation procedures, LexSym can be deployed agnostically across text, structured data, and even images. It matches or surpasses state-of-the-art, task-specific models on COGS semantic parsing, SCAN and Alchemy instruction following, and CLEVR-CoGenT visual question answering datasets.
Cite (Informal):LexSym: Compositionality as Lexical Symmetry (Akyurek & Andreas, ACL 2023)
Year:2023
Venue:ACL
Anthology ID:2023.acl-long.38
Bibkey:akyurek-andreas-2023-lexsym
Volume:Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
URL:https://aclanthology.org/2023.acl-long.38
PDF:https://aclanthology.org/2023.acl-long.38.pdf
Month:July
SIG:
Address:Toronto, Canada
Language:
Cite (ACL):Ekin Akyurek and Jacob Andreas. 2023. LexSym: Compositionality as Lexical Symmetry. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 639–657, Toronto, Canada. Association for Computational Linguistics.
Editors:Anna Rogers,Jordan Boyd-Graber,Naoaki Okazaki
Note:
Pages:639–657
DOI:10.18653/v1/2023.acl-long.38
Publisher:Association for Computational Linguistics
BibTex: @inproceedings{akyurek-andreas-2023-lexsym,
    title = "{L}ex{S}ym: Compositionality as Lexical Symmetry",
    author = "Akyurek, Ekin  and
      Andreas, Jacob",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.38",
    doi = "10.18653/v1/2023.acl-long.38",
    pages = "639--657",
    abstract = "In tasks like semantic parsing, instruction following, and question answering, standard deep networks fail to generalize compositionally from small datasets. Many existing approaches overcome this limitation with model architectures that enforce a compositional process of sentence interpretation. In this paper, we present a domain-general and model-agnostic formulation of compositionality as a constraint on symmetries of data distributions rather than models. Informally, we prove that whenever a task can be solved by a compositional model, there is a corresponding data augmentation scheme {---} a procedure for transforming examples into other well-formed examples {---} that imparts compositional inductive bias on any model trained to solve the same task. We describe a procedure called LexSym that discovers these transformations automatically, then applies them to training data for ordinary neural sequence models. Unlike existing compositional data augmentation procedures, LexSym can be deployed agnostically across text, structured data, and even images. It matches or surpasses state-of-the-art, task-specific models on COGS semantic parsing, SCAN and Alchemy instruction following, and CLEVR-CoGenT visual question answering datasets.",
}

Title: On Evaluating Multilingual Compositional Generalization with Translated Datasets
Authors: Zi Wang, Daniel Hershcovich
Abstract: Compositional generalization allows efficient learning and human-like inductive biases. Since most research investigating compositional generalization in NLP is done on English, important questions remain underexplored. Do the necessary compositional generalization abilities differ across languages? Can models compositionally generalize cross-lingually? As a first step to answering these questions, recent work used neural machine translation to translate datasets for evaluating compositional generalization in semantic parsing. However, we show that this entails critical semantic distortion. To address this limitation, we craft a faithful rule-based translation of the MCWQ dataset from English to Chinese and Japanese. Even with the resulting robust benchmark, which we call MCWQ-R, we show that the distribution of compositions still suffers due to linguistic divergences, and that multilingual models still struggle with cross-lingual compositional generalization. Our dataset and methodology will serve as useful resources for the study of cross-lingual compositional generalization in other tasks.
Cite (Informal):On Evaluating Multilingual Compositional Generalization with Translated Datasets (Wang & Hershcovich, ACL 2023)
Year:2023
Venue:ACL
Anthology ID:2023.acl-long.93
Bibkey:wang-hershcovich-2023-evaluating
Volume:Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
URL:https://aclanthology.org/2023.acl-long.93
PDF:https://aclanthology.org/2023.acl-long.93.pdf
Month:July
SIG:
Address:Toronto, Canada
Language:
Cite (ACL):Zi Wang and Daniel Hershcovich. 2023. On Evaluating Multilingual Compositional Generalization with Translated Datasets. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1669–1687, Toronto, Canada. Association for Computational Linguistics.
Editors:Anna Rogers,Jordan Boyd-Graber,Naoaki Okazaki
Note:
Pages:1669–1687
DOI:10.18653/v1/2023.acl-long.93
Publisher:Association for Computational Linguistics
BibTex: @inproceedings{wang-hershcovich-2023-evaluating,
    title = "On Evaluating Multilingual Compositional Generalization with Translated Datasets",
    author = "Wang, Zi  and
      Hershcovich, Daniel",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.93",
    doi = "10.18653/v1/2023.acl-long.93",
    pages = "1669--1687",
    abstract = "Compositional generalization allows efficient learning and human-like inductive biases. Since most research investigating compositional generalization in NLP is done on English, important questions remain underexplored. Do the necessary compositional generalization abilities differ across languages? Can models compositionally generalize cross-lingually? As a first step to answering these questions, recent work used neural machine translation to translate datasets for evaluating compositional generalization in semantic parsing. However, we show that this entails critical semantic distortion. To address this limitation, we craft a faithful rule-based translation of the MCWQ dataset from English to Chinese and Japanese. Even with the resulting robust benchmark, which we call MCWQ-R, we show that the distribution of compositions still suffers due to linguistic divergences, and that multilingual models still struggle with cross-lingual compositional generalization. Our dataset and methodology will serve as useful resources for the study of cross-lingual compositional generalization in other tasks.",
}

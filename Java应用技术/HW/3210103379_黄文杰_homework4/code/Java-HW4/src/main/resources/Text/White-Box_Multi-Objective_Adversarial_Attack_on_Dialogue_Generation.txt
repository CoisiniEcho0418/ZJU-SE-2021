Title: White-Box Multi-Objective Adversarial Attack on Dialogue Generation
Authors: Yufei Li, Zexin Li, Yingfan Gao, Cong Liu
Abstract: Pre-trained transformers are popular in state-of-the-art dialogue generation (DG) systems. Such language models are, however, vulnerable to various adversarial samples as studied in traditional tasks such as text classification, which inspires our curiosity about their robustness in DG systems. One main challenge of attacking DG models is that perturbations on the current sentence can hardly degrade the response accuracy because the unchanged chat histories are also considered for decision-making. Instead of merely pursuing pitfalls of performance metrics such as BLEU, ROUGE, we observe that crafting adversarial samples to force longer generation outputs benefits attack effectiveness—the generated responses are typically irrelevant, lengthy, and repetitive. To this end, we propose a white-box multi-objective attack method called DGSlow. Specifically, DGSlow balances two objectives—generation accuracy and length, via a gradient-based multi-objective optimizer and applies an adaptive searching mechanism to iteratively craft adversarial samples with only a few modifications. Comprehensive experiments on four benchmark datasets demonstrate that DGSlow could significantly degrade state-of-the-art DG models with a higher success rate than traditional accuracy-based methods. Besides, our crafted sentences also exhibit strong transferability in attacking other models.
Cite (Informal):White-Box Multi-Objective Adversarial Attack on Dialogue Generation (Li et al., ACL 2023)
Year:2023
Venue:ACL
Anthology ID:2023.acl-long.100
Bibkey:li-etal-2023-white
Volume:Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
URL:https://aclanthology.org/2023.acl-long.100
PDF:https://aclanthology.org/2023.acl-long.100.pdf
Month:July
SIG:
Address:Toronto, Canada
Language:
Cite (ACL):Yufei Li, Zexin Li, Yingfan Gao, and Cong Liu. 2023. White-Box Multi-Objective Adversarial Attack on Dialogue Generation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1778–1792, Toronto, Canada. Association for Computational Linguistics.
Editors:Anna Rogers,Jordan Boyd-Graber,Naoaki Okazaki
Note:
Pages:1778–1792
DOI:10.18653/v1/2023.acl-long.100
Publisher:Association for Computational Linguistics
BibTex: @inproceedings{li-etal-2023-white,
    title = "White-Box Multi-Objective Adversarial Attack on Dialogue Generation",
    author = "Li, Yufei  and
      Li, Zexin  and
      Gao, Yingfan  and
      Liu, Cong",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.100",
    doi = "10.18653/v1/2023.acl-long.100",
    pages = "1778--1792",
    abstract = "Pre-trained transformers are popular in state-of-the-art dialogue generation (DG) systems. Such language models are, however, vulnerable to various adversarial samples as studied in traditional tasks such as text classification, which inspires our curiosity about their robustness in DG systems. One main challenge of attacking DG models is that perturbations on the current sentence can hardly degrade the response accuracy because the unchanged chat histories are also considered for decision-making. Instead of merely pursuing pitfalls of performance metrics such as BLEU, ROUGE, we observe that crafting adversarial samples to force longer generation outputs benefits attack effectiveness{---}the generated responses are typically irrelevant, lengthy, and repetitive. To this end, we propose a white-box multi-objective attack method called DGSlow. Specifically, DGSlow balances two objectives{---}generation accuracy and length, via a gradient-based multi-objective optimizer and applies an adaptive searching mechanism to iteratively craft adversarial samples with only a few modifications. Comprehensive experiments on four benchmark datasets demonstrate that DGSlow could significantly degrade state-of-the-art DG models with a higher success rate than traditional accuracy-based methods. Besides, our crafted sentences also exhibit strong transferability in attacking other models.",
}

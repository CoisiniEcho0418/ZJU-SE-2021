# 探究大语言模型对汇编指令的理解程度

------

## 一、背景说明

随着自然语言处理技术的飞速发展，大语言模型（LLMs）在多个领域取得了显著成果，从文本生成到自动翻译，它们的应用范围不断扩展。近年来，尤其是在编程语言和代码理解方面，LLMs 的表现也引起了广泛关注。汇编语言作为计算机体系结构中最底层的语言之一，广泛用于系统编程、嵌入式开发以及性能优化等领域。掌握汇编语言的解析和生成，对于理解计算机底层操作、提升编程技能具有重要意义。

然而，尽管大语言模型在高层次语言（如 Python、Java）中表现优异，其对汇编语言的理解和生成能力仍然存在一定的挑战。汇编语言具有较为复杂的语法和操作，涉及到寄存器操作、寻址模式、指令集等多个细节。大语言模型能否有效理解和生成符合语法和功能要求的汇编代码，仍是一个亟待解决的问题。

本项目旨在探讨大语言模型（如 ChatGPT、Kimi,、豆包等）在理解和生成汇编指令集方面的能力。通过构建汇编指令测试序列，并评估大语言模型对指令、计算结果以及状态标志更新等概念的理解，本项目期望能够揭示当前大语言模型在汇编语言领域的局限性，并为未来汇编语言处理的研究和应用提供借鉴。

本研究的重点将放在以下几个方面：构建一些具有复杂度的汇编指令集（x86汇编），分析大语言模型对不同指令的理解程度；探索模型在理解指令执行结果、状态位更新等方面的能力；尝试修正模型的理解错误，并识别常见的错误模式。



## 二、探索过程

首先我将以课上给出的汇编例子对如下四款大语言模型进行测试（ChatGPT/DeepSeek Coder/Kimi/doubao）。

### 汇编指令测试集case 1

```assembly
MOV AL, '3'
ADD AL, '4'
AAA
```

#### **<u>ChatGPT</u>**

![image-20241227222816752](./assets/image-20241227222816752.png)



**结果分析：**

由图可见，ChatGPT对AL低4位大于9错位地理解成了AL大于0x09，以至于后续所有结果都错了，而且AL寄存器高四位也没有被置零，可见该版本的GPT对AAA指令的理解程度较低。



#### <u>DeepSeek Coder</u>

![image-20241227223311473](./assets/image-20241227223311473.png)

**结果分析：**

有点意外的是，DeepSeek Coder大模型居然给出了很正确的答案，不仅没有犯低级算术运算错误，也没有错误地忽略状态位的设置和AL高位清零这些步骤。



#### <u>Kimi</u>

![image-20241227224022552](./assets/image-20241227224022552.png)

**结果分析：**

Kimi大模型和ChatGPT犯了一样的错误，在7>9这样的算术判断上都无法给出正确的结果，导致后续的一系列逻辑判断都出错。而且很明显的看到，Kimi甚至对低位加6这样的操作都没有理解，可见其对AAA这样的汇编指令没有理解透彻。



#### <u>doubao</u>

![image-20241228000925843](./assets/image-20241228000925843.png)

**结果分析：**

豆包模型的结果大致是对的，但中间还是有些小的逻辑错误，比如低4位大于9时，应该把AL高4位清零，然后给AH寄存器置1。虽然结果是对的，但是无法准确地评估它对AAA汇编指令的理解程度，所以在效果分析环节将会换测试用例来考察它对AAA指令的理解程度。



### 汇编指令测试集case 2

该次实验将测试大模型对跳转汇编指令的理解程度，以及是否具备根据要求识别指令代码存在的问题并采取纠正的能力。测试代码集引自课程PPT：

该代码要求实现控制温度的功能（将温度控制在15℃-25℃间），但是代码存在问题，需要纠正。

```assembly
.code 
start:
 in al, 125 ; read temperature
 
 cmp al, 15
 jb low
 
 cmp al, 25
 ja high
 
 jmp start
 
low:
 mov al, 1
 out 127, al ; turn on heater
 jmp start
 
high:
 mov al, 0
 out 127, al ; turn off heater
 jmp start
 
 hlt
 
.exit
```

由case 1的探索发现DeepSeek Coder对汇编指令的理解比其他几款大模型好，所以这次测试示例只针对ChatGPT和DeepSeek Coder这两款大模型进行。

#### <u>ChatGPT</u>

![image-20241228015345524](./assets/image-20241228015345524.png)

**结果分析：**

可见ChatGPT未能正确识别代码存在的问题，并且提供的修改建议也不太行。



#### <u>DeepSeek Coder</u>

![image-20241228015630840](./assets/image-20241228015630840.png)

**结果分析：**

从结果来看，虽然DeepSeek Coder在case 1的表现好于其他几款大模型，但是在针对特定场景的问题纠错时，它也未必能完全给出正确的解答。



## 三、效果分析

对大模型的纠错和深入探究之前，我会直接询问大模型对某条指令的解释，来看看它对单独一条指令的理解如何，然后再循序渐进的对其纠错，从而发现或者推测大模型幻觉产生的原因。

### case 1 纠错&深入探究

#### **<u>ChatGPT</u>**

从上面探索过程可知ChatGPT对AAA汇编指令的理解程度不够，所以需要对他进行纠错。我将采用循序渐进的方式来引导他（程度从委婉到直接）。

##### 指令解释阶段

![image-20241227231532859](./assets/image-20241227231532859.png)

**结果分析：**

ChatGPT对指令的解释有点奇怪，它对AL低4位大于9错位地理解成了AL大于0x09，从而使结果出现偏差，并且不知道AL高四位要清零。但是从他给出的两个例子中可以发现，它在某些情况下可以给出正确的答案（包括AL高四位清零，AF/CF/AH置1），但有的情况却又不知道高4位清零，并且结果也是错的。



##### 纠错阶段

![image-20241227233356222](./assets/image-20241227233356222.png)

**总结分析：**

大模型对对某些汇编指令（比如AAA）的理解不太深刻，有些细节方面出现了理解偏差，并且大模型再算术逻辑运算方面有缺陷，连7<9这样的比较结果都无法正确判断，从而导致汇编指令运算结果出现偏差。



#### <u>DeepSeek Coder</u>

##### 指令解释阶段

![image-20241227234238330](./assets/image-20241227234238330.png)

**结果分析：**

从DeepSeek Coder的解释来看，其对AAA指令的理解程度好于ChatGPT，但是其中有个小细节它阐述有点问题：如果 `AL` 的低4位（`AL & 0x0F`）大于9，或者辅助进位标志 `AF` 为1时，它对AH的调整理解成了AH = AH + 1，但实际上应该是AH = 1，这里有点偏差，需要后续设置用例进行测试。



##### 深层测试阶段

![image-20241227235020567](./assets/image-20241227235020567.png)

**总结分析：**

设置额外的测试用例之后发现，针对AH初始值为1 的情况，该模型的确会按照AH=AH+1的步骤来调整，但是根据老师PPT上的阐述，AH应该被直接置1，所以这里可能有点偏差。



#### <u>Kimi</u>

##### 指令解释阶段

![image-20241227235433796](./assets/image-20241227235433796.png)

**结果分析：**

可以看见Kimi大模型对AAA指令的理解程度比ChatGPT还差，所以需要直接帮他梳理AAA的作用和内部机理。



##### 纠错阶段

![image-20241228000659585](./assets/image-20241228000659585.png)

**总结分析：**

再纠正其对指令的理解之后，Kimi已经能够正确给出答案，并且能够举一反三。



#### <u>doubao</u>

##### 指令解释阶段

![image-20241228001035821](./assets/image-20241228001035821.png)

**结果分析：**

结果同Kimi，本质还是对AAA指令的内部机理理解有偏差，需要进行纠正。



##### 纠错阶段

![image-20241228001508196](./assets/image-20241228001508196.png)

**总结分析：**

在发现大模型对指令的理解有偏差时，采取重新帮助理解指令机理的方式能够最快速有效地帮助大模型消除幻觉，正确运行汇编指令集并得到准确的结果。



### case 2 纠错&深入探究

由于大模型未能正确找出代码存在的问题，所以需要先理清楚其对一些关键指令的理解程度，然后再采取针对性的纠正措施。

#### **<u>ChatGPT</u>**

##### **指令解释阶段**

![image-20241228020154817](./assets/image-20241228020154817.png)

**结果分析：**

ChatGPT对ja、jb、jl的理解没有任何问题，但是对于jg的理解有偏差（虽然对于发现并纠正代码缺陷的影响不大）。由此可见ChatGPT无法完成代码缺陷纠正的深层原因不在于对指令理解的不够而在于对分支判断无法做到全场景覆盖，从而倒推不出可能出现问题的case。



##### 纠错阶段

需要先纠正ChatGPT对jg指令的理解偏差，然后再引导它思考代码可能出现缺陷的分支场景。

![image-20241228022400214](./assets/image-20241228022400214.png)

**总结分析：**

对于ChatGPT来说，只是委婉地告诉大模型可能需要更换的指令不足以让它完全联想到可能出现问题的场景，只有指明某个分支场景才能让大模型意识到代码可能出现的问题并做出正确的改正。



#### <u>DeepSeek Coder</u>

##### 指令解释阶段

![image-20241228020719440](./assets/image-20241228020719440.png)

**结果分析：**

DeepSeek Coder能够理解四条关键跳转指令的作用和内部机理，因而它发现不了代码错误的原因不在于对指令的理解偏差而在于对逻辑判断和case覆盖的缺陷，换句话说，大模型目前对于分支判断无法做到全场景覆盖，所以对于需要利用全分支覆盖来解答的场景，大模型目前还无能为力。



##### 纠错阶段

![image-20241228022805331](./assets/image-20241228022805331.png)

**总结分析：**

与ChatGPT对比可以发现，DeepSeek Coder无论从汇编指令理解的准确度还是联想能力都比ChatGPT要强，对于DeepSeek Coder来说，只需要委婉地提示即可让它意识到可能出错的场景。由此说明目前已经有大模型具备了一定的联想关联能力。



## 四、实验体会

由于时间精力有限，在本实验我只针对两个比较简单的case做了探究，但通过对比不同的LLM产生的结果以及深入地纠错和探索，我收获的结论也不少。

1. 通过对比实验，可以很明显地发现不同的LLM之间能力有很大的差异，其中DeepSeek Coder对于汇编指令的理解能力和关联推理能力都好于其他几个模型。
2. 目前的大模型对于一些比较少见的汇编指令（如AAA），可能存在理解不准确的情况，从而导致其无法正确预测执行结果。
3. LLM对算术运算的能力还是稍微差一点，就算是一些简单的大小比较也可能出现幻觉（比如无法正确地判断7和9的大小）。
4. 对于case 2的探究可以发现，目前大模型对于分支覆盖和推理能力还有所缺陷，就算是比较简单的双分支判断也无法想象出全部用例去覆盖场景来倒推结果，从而使得其在纠错方面有所缺陷。但欣慰的是，通过对DeepSeek Coder的探索，可以初步看出其已具备一定的联想关联能力，因而对于纠错的场景来说在未来也是有可能实现很高的成功率的。



## 五、经验教训

最好不要使用大模型去做一些算术运算，因为无论是自己先前的经验教训还是这次的探究过程，我都很明显地发现大模型其实对于算术运算的能力还是有点欠缺的，甚至连一些简单的大小逻辑判断都有可能出问题，更别提复杂度更高的数学运算了。所以还是尽可能地避免让大模型涉及复杂的算术运算，这样它才能更好地发挥它的功能。



## 六、参考文献

- Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code, https://arxiv.org/abs/2311.07989
- Awesome-Code-LLM : https://github.com/codefuse-ai/Awesome-Code-LLM

- Mankowitz, Daniel J., et al. "Faster sorting algorithms discovered using deep reinforcement learning." Nature 618.7964 (2023): 257-263.
- DeepSeek Coder: https://www.deepseek.com
- ChatGPT: https://chatgpt.com/
- Kimi: [Kimi.ai - 会推理解析，能深度思考的AI助手](https://kimi.moonshot.cn/)
- doubao: [豆包 - 字节跳动旗下 AI 智能助手](https://www.doubao.com/chat/)